# Glosario

## L

### LLM (Large Language Model)
**Large Language Model** - Modelo de Lenguaje Grande. Sistema de inteligencia artificial entrenado para entender y generar texto humano de manera natural. Es una red neuronal entrenada con enormes cantidades de texto que aprendi√≥ a predecir qu√© palabra viene despu√©s en cualquier contexto. Con esa habilidad simple, desarroll√≥ capacidades complejas como escribir, programar, explicar, traducir y conversar.

**Caracter√≠sticas:**
- Proces√≥ millones de textos para aprender patrones del lenguaje
- Disponible 24/7 sin cansarse
- Puede cometer errores o generar informaci√≥n incorrecta
- Funciona mediante predicci√≥n de texto avanzada

## P

### Prompt
Instrucci√≥n o mensaje que se le da a un LLM para obtener una respuesta espec√≠fica. Es la entrada de texto que gu√≠a al modelo hacia el resultado deseado.

### Prompt Engineering (Ingenier√≠a R√°pida)
Disciplina emergente centrada en dise√±ar, optimizar y refinar instrucciones (prompts) para hacer buen uso de LLMs con el fin de obtener respuestas m√°s precisas, seguras y adaptadas a necesidades espec√≠ficas.

**Beneficios:**
- ‚úÖ Mejorar habilidades existentes del LLM
- üöÄ Aumentar conocimiento sin reentrenar
- üîç Descubrir capacidades ocultas
- üéØ Optimizar calidad de salidas

## F

### Few-shot Learning
T√©cnica b√°sica de prompt engineering que consiste en proporcionar ejemplos de entrada/salida para demostrar el formato y estilo deseado al modelo.

**Estructura:**
```
[Instrucci√≥n general]
Ejemplo 1:
Input: [entrada 1]
Output: [salida deseada 1]

Ejemplo 2:
Input: [entrada 2]
Output: [salida deseada 2]

Input: [nueva entrada]
Output:
```

## C

### Contextualizaci√≥n
T√©cnica b√°sica de prompt engineering que establece un rol o escenario para guiar la perspectiva del modelo.

**Estructura:** "Como [rol/especialista], [acci√≥n] [contexto]"

## T

### ToT (Tree of Thoughts - √Årbol de Pensamientos)
T√©cnica avanzada de razonamiento donde el modelo explora m√∫ltiples caminos de soluci√≥n simult√°neamente, estructurando el proceso como un √°rbol de posibilidades.

**Proceso:**
1. **Ramificaci√≥n:** Genera m√∫ltiples opciones/soluciones en cada nodo
2. **Evaluaci√≥n:** Califica cada rama con m√©tricas espec√≠ficas
3. **Poda:** Elimina ramas no viables bas√°ndose en evaluaciones
4. **Selecci√≥n:** Elige el mejor camino mediante an√°lisis comparativo


### Temperatura
**Temperatura** - Par√°metro de configuraci√≥n en los LLMs que controla el grado de aleatoriedad (o "creatividad") en las respuestas generadas. T√©cnicamente, modifica la distribuci√≥n de probabilidad durante el muestreo de tokens.

**Caracter√≠sticas principales:**
- **Escala**: Generalmente entre 0 y 1, aunque algunos sistemas permiten valores m√°s altos
- **Temperatura baja (0-0.3)**: Respuestas m√°s predecibles, determin√≠sticas y conservadoras
- **Temperatura media (0.4-0.7)**: Balance entre creatividad y coherencia
- **Temperatura alta (0.8-1.0+)**: Mayor variabilidad, creatividad y potencial sorpresa

**Cu√°ndo usar diferentes valores:**
- **Temperatura 0**: Para tareas que requieren precisi√≥n absoluta como c√≥digo, matem√°ticas o informaci√≥n factual
- **Temperatura 0.2-0.4**: Para res√∫menes, respuestas t√©cnicas y explicaciones formales
- **Temperatura 0.5-0.7**: Para contenido general, emails y textos conversacionales
- **Temperatura 0.8+**: Para contenido creativo como poes√≠a, historias, ideas divergentes o brainstorming

**Nota importante**: La temperatura no afecta el "conocimiento" del modelo, solo c√≥mo se seleccionan las palabras entre las opciones probables. Un valor alto no hace que el modelo sea m√°s inteligente, solo m√°s impredecible.

## S

### Self-Consistency (Autoconsistencia)
T√©cnica donde el modelo genera m√∫ltiples l√≠neas de razonamiento, eval√∫a cada camino independientemente y selecciona la respuesta m√°s consistente entre variantes.

**Beneficios:**
- Reduce errores en problemas complejos
- Minimiza sesgos en decisiones t√©cnicas
- Combina perspectivas complementarias
- Detecta contradicciones internas

## R

### RAG (Generaci√≥n Aumentada de Recuperaci√≥n)
T√©cnica de prompting donde se incluye informaci√≥n espec√≠fica en el prompt para que el AI genere respuestas m√°s precisas y verificables.

**F√≥rmula:** Informaci√≥n relevante + Instrucciones claras + Pregunta = Respuesta fundamentada

**Estructura b√°sica:**
```
# INFORMACI√ìN BASE
[Datos, documentos o c√≥digo relevante]

# INSTRUCCIONES
- Usa solo la informaci√≥n proporcionada
- Cita las fuentes
- Si falta info, dilo claramente

# PREGUNTA
[Tu consulta espec√≠fica]
```

## I

### Instrucciones Expl√≠citas
Comandos directos que especifican acciones concretas usando verbos imperativos.

**Estructura:** "[Verbo imperativo] [objeto] [par√°metros]"

**Ejemplos:**
- "Resume este texto en 3 oraciones m√°ximas"
- "Compara X e Y usando tabla de dos columnas"
- "Clasifica este sentimiento: positivo, neutral o negativo"

## E

### Especificaci√≥n de Formato
T√©cnica que indica c√≥mo estructurar la respuesta del modelo.

**Estructura:** "[Instrucci√≥n] usando formato [tipo] con [elementos]"

**Ejemplos:**
- "Responde en JSON con claves: resumen, ventajas, desventajas"
- "Genera lista numerada con emojis para cada punto"
- "Organiza en secciones con encabezados ##"

## L

### Limitaci√≥n de Alcance
T√©cnica que restringe longitud, profundidad o aspectos de la respuesta.

**Estructura:** "[Instrucci√≥n] [restricci√≥n] [par√°metros]"

**Ejemplos:**
- "Explica en m√°ximo 100 palabras"
- "Enumera solo 3 ventajas principales"
- "Responde con met√°fora simple"